## Real-Time Analytics Architect ğŸ›°ï¸ğŸ“Š

An interactive, front-end visualization of a modern real-time data stackâ€”the kind shipping production insights for curb-side, e-commerce, IoT, gaming and beyond.  
Click any node to see live KPIs, lineage, and plain-English explanations of how each component works together.

---

## âœ¨ Why This Project Stands Out
- **Full Streaming Pipeline, End-to-End** â€“ Shows event ingestion âœ streaming compute âœ speed & batch layers âœ semantic modeling âœ forecasting âœ BI.
- **Hands-on With Hot Tech** â€“ Kafka, Spark Structured Streaming, Snowflake, dbt, Prophet/ARIMA, Power BI, plus a React/Vite TypeScript front-end.
- **Cloud-Ready** â€“ Built and tested on AWS (EKS/Fargate + MSK + Snowflake + S3/CloudFront) but provider-agnostic.
- **AI-Powered Explanations** â€“ Uses Gemini 1.5 Pro to generate human-readable descriptions for each architecture component.
- **Recruiter-Friendly** â€“ Clean repo, clear docs, one-command local spin-up, and a demo deploy script.

---

## ğŸ—ï¸ Architecture At A Glance
```mermaid
flowchart LR
  subgraph Ingestion
    PYP["Python Event Producer"]
    PYP --> KAF[Kafka]
  end

  subgraph Stream Processing
    KAF --> SPK[Spark Structured Streaming]
    SPK --> SPEED[Snowflake (Speed Layer)]
  end

  SPK --> BATCH[Snowflake (DWH)]
  BATCH --> DBT[dbt Transformations]
  DBT --> PRP[Prophet/ARIMA Forecasts]
  PRP --> RECO[Staffing Recommender]
  RECO --> ALERT[Teams Alerts]

  BATCH --> BI[Power BI Dashboard]
ğŸ”‘ Key Components & Features
Layer	Tech	What It Demonstrates
Ingestion	Python Producer + Apache Kafka	Schema registry, exactly-once semantics
Stream Compute	Spark Structured Streaming	Windowed aggregations, watermarking
Speed Layer	Snowflake	Low-latency query serving
Batch Layer	Snowflake DWH	Column-store analytics @ scale
Transform	dbt	Version-controlled SQL models & tests
ML / Forecast	Prophet / ARIMA	Predictive staffing recommendations
Alerting	Microsoft Teams Webhook	Ops feedback loop
BI	Power BI	Real-time dashboards & KPI cards

ğŸš€ Quick Start
Prerequisites
Node >= 18

npm or pnpm

Optional: Snowflake account & Kafka cluster (code includes docker-compose for local testing)


Local Run
bash
Copy
Edit
# 1. Install dependencies
npm i          # or pnpm i

# 2. Configure env
cp .env.local.example .env.local     # add your keys

# 3. Launch dev server
npm run dev
Navigate to http://localhost:5173 and click nodes to explore metrics.

One-Click AWS Deploy
bash
Copy
Edit
./scripts/deploy_aws.sh \
  --bucket rt-analytics-$(aws sts get-caller-identity --query 'Account' --output text) \
  --region us-east-1
Creates an S3 + CloudFront static site, provisions MSK topic & Lambda consumer, and streams demo events.

ğŸ“‚ Repo Structure
bash
Copy
Edit
.
â”œâ”€â”€ components/            # React components (ArchitectureNode, LiveDashboardâ€¦)
â”œâ”€â”€ services/              #  data-fetch helpers
â”œâ”€â”€ scripts/               # Local simulator + AWS CDK deploy
â”œâ”€â”€ types.ts               # Shared TypeScript types
â”œâ”€â”€ constants.tsx          # Architecture graph definition
â”œâ”€â”€ App.tsx                # Main layout
â””â”€â”€ README.md
ğŸ§ª Tests & Quality
Vitest unit tests for helper utilities

Playwright e2e flow (architecture clicks + explanation overlay)

ESLint + Prettier enforced via pre-commit hook

Run locally:

bash
Copy
Edit
npm run test        # unit tests
npm run test:e2e    # end-to-end
npm run lint
ğŸ¤ Contributing
Fork â†’ Create Branch â†’ Commit â†’ PR

Follow the commit style feat(scope): message (Conventional Commits)

New architecture nodes? Extend ARCHITECTURE_COMPONENTS_LIST in constants.tsx.
